{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ⾃动求梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from mxnet import autograd, nd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 简单例⼦\n",
    "对函数 $y = 2x^⊤x$ 求关于列向量 $x$ 的梯度。\n",
    "1. 我们先创建变量x，并赋初值\n",
    "2. 为了求有关变量x的梯度，我们需要先调⽤`attach_grad`函数来申请存储梯度所需要的内存\n",
    "3. 下⾯定义有关变量x的函数。为了减少计算和内存开销，默认条件下MXNet不会记录⽤于求梯度\n",
    "的计算。我们需要调⽤record函数来要求MXNet记录与求梯度有关的计算\n",
    "4. 由于x的形状为（4, 1），y是⼀个标量。接下来我们可以通过调⽤backward函数⾃动求梯度。需\n",
    "要注意的是，如果y不是⼀个标量，MXNet将默认先对y中元素求和得到新的变量，再求该变量有\n",
    "关x的梯度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "\n[[0.]\n [1.]\n [2.]\n [3.]]\n<NDArray 4x1 @cpu(0)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "x = nd.arange(4).reshape(4,1)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "x.attach_grad()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with(autograd.record()):\n",
    "    y = 2*nd.dot(x.T, x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "y.backward()    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "函数 $y = 2x^⊤x$ 关于$x$ 的梯度应为$4x$。现在我们来验证⼀下求出来的梯度是正确的"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "\n[[ 0.]\n [ 4.]\n [ 8.]\n [12.]]\n<NDArray 4x1 @cpu(0)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "assert (x.grad - 4*x).norm().asscalar() == 0\n",
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练模式和预测模式\n",
    "在调⽤record函数后，MXNet会记录并计算梯度。此外，默认情况下autograd还\n",
    "会将运⾏模式从预测模式转为训练模式。这可以通过调⽤is_training函数来查看"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "False\nTrue\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(autograd.is_training())\n",
    "with(autograd.record()):\n",
    "    print(autograd.is_training())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 对Python控制流求梯度\n",
    "使⽤MXNet的⼀个便利之处是，即使函数的计算图包含了Python的控制流（如条件和循环控制），\n",
    "我们也有可能对变量求梯度。\n",
    "考虑下⾯程序，其中包含Python的条件和循环控制。需要强调的是，这⾥循环（while循环）迭\n",
    "代的次数和条件判断（if语句）的执⾏都取决于输⼊a的值。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm().asscalar() < 1000:\n",
    "        b = b * 2\n",
    "        if b.sum().asscalar() > 0:\n",
    "            c = b\n",
    "        else:\n",
    "            c = 100 * b\n",
    "    return c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们像之前⼀样使⽤record函数记录计算，并调⽤backward函数求梯度。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "a = nd.random.normal(shape=1)\n",
    "a.attach_grad()\n",
    "with(autograd.record()):\n",
    "    c = f(a)\n",
    "c.backward()    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "\n[1.]\n<NDArray 1 @cpu(0)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "a.grad == c/a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- MXNet提供`autograd`模块来⾃动化求导过程。\n",
    "- MXNet的`autograd`模块可以对⼀般的命令式程序进⾏求导。\n",
    "- MXNet的运⾏模式包括训练模式和预测模式。我可以通过`autograd.is_training()`来判断运⾏模式"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 查阅文档\n",
    "### 查找模块⾥的所有函数和类\n",
    "当我们想知道⼀个模块⾥⾯提供了哪些可以调⽤的函数和类的时候，可以使⽤`dir`函数。下⾯我\n",
    "们打印`nd.random`模块中所有的成员或属性"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['NDArray', '_Null', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_internal', '_random_helper', 'current_context', 'exponential', 'exponential_like', 'gamma', 'gamma_like', 'generalized_negative_binomial', 'generalized_negative_binomial_like', 'multinomial', 'negative_binomial', 'negative_binomial_like', 'normal', 'normal_like', 'numeric_types', 'poisson', 'poisson_like', 'randint', 'randn', 'shuffle', 'uniform', 'uniform_like']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(dir(nd.random))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 查找特定函数和类的使⽤\n",
    "想了解某个函数或者类的具体⽤法时，可以使⽤`help`函数。让我们以NDArray中的`ones_like`函\n",
    "数为例，查阅它的⽤法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Help on function ones_like:\n\nones_like(data=None, out=None, name=None, **kwargs)\n    Return an array of ones with the same shape and type\n    as the input array.\n    \n    Examples::\n    \n      x = [[ 0.,  0.,  0.],\n           [ 0.,  0.,  0.]]\n    \n      ones_like(x) = [[ 1.,  1.,  1.],\n                      [ 1.,  1.,  1.]]\n    \n    \n    \n    Parameters\n    ----------\n    data : NDArray\n        The input\n    \n    out : NDArray, optional\n        The output NDArray to hold the result.\n    \n    Returns\n    -------\n    out : NDArray or list of NDArrays\n        The output of this function.\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "help(nd.ones_like)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "\n[[1. 1. 1.]\n [1. 1. 1.]]\n<NDArray 2x3 @cpu(0)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "x = nd.array([[0, 0, 0], [2, 2, 2]])\n",
    "y = x.ones_like()\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在Jupyter记事本⾥，我们可以使⽤?来将⽂档显⽰在另外⼀个窗口中。例如，使⽤nd.random.\n",
    "uniform?将得到与help(nd.random.uniform)⼏乎⼀样的内容，但会显⽰在额外窗口⾥。此\n",
    "外，如果使⽤nd.random.uniform??，那么会额外显⽰该函数实现的代码"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "nd.uniform?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "nd.uniform??"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 在MXNet⽹站上查阅\n",
    "可以在MXNet的⽹站上查阅相关⽂档。访问[MXNet⽹站](http://mxnet.apache.org/)\n",
    "点击⽹⻚顶部的下拉菜单“API”可查阅各个前端语⾔的接口。此外，也可以在⽹⻚\n",
    "右上⽅含“Search”字样的搜索框中直接搜索函数或类名称。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 多层感知机\n",
    "我们已经介绍了包括线性回归和softmax回归在内的单层神经⽹络。然而深度学习主要关注多层\n",
    "模型。在本节中，我们将以多层感知机（multilayer perceptron， MLP）为例，介绍多层神经⽹\n",
    "络的概念。\n",
    "## 隐藏层\n",
    "多层感知机在单层神经⽹络的基础上引⼊了⼀到多个隐藏层（hidden layer）。隐藏层位于输⼊层\n",
    "和输出层之间。下图展⽰了⼀个多层感知机的神经⽹络图\n",
    "\n",
    "![带有隐藏层的多层感知机。它含有一个隐藏层，该层中有5个隐藏单元](../img/mlp.svg)\n",
    "\n",
    "在图中所⽰的多层感知机中，输⼊和输出个数分别为4和3，中间的隐藏层中包含了5个隐藏单元\n",
    "（hidden unit）。由于输⼊层不涉及计算，图中的多层感知机的层数为2。由图可⻅，隐藏层\n",
    "中的神经元和输⼊层中各个输⼊完全连接，输出层中的神经元和隐藏层中的各个神经元也完全连\n",
    "接。因此，多层感知机中的隐藏层和输出层都是全连接层。\n",
    "\n",
    "具体来说，给定⼀个小批量样本$\\boldsymbol{X} \\in \\boldsymbol{\\mathbb{R}}^{n×d}$，其批量⼤小为$n$，输⼊个数为$d$。假设多层感知机只\n",
    "有⼀个隐藏层，其中隐藏单元个数为$h$。记隐藏层的输出（也称为隐藏层变量或隐藏变量）为$\\boldsymbol H$，\n",
    "有$\\boldsymbol{H} \\in \\boldsymbol{\\mathbb{R}}^{n×h}$。因为隐藏层和输出层均是全连接层，可以设隐藏层的权重参数和偏差参数分别\n",
    "为$\\boldsymbol{W}_h \\in \\boldsymbol{\\mathbb{R}}^{d×h}$和$\\boldsymbol{b}_h \\in \\boldsymbol{\\mathbb{R}}^{1×h}$，输出层的权重和偏差参数分别为$\\boldsymbol{W}_o \\in \\boldsymbol{\\mathbb{R}}^{h×q}和\\boldsymbol{b}_o \\in \\boldsymbol{\\mathbb R}^{1×q}$。\n",
    "我们先来看⼀种含单隐藏层的多层感知机的设计。其输出$\\boldsymbol{W}_o \\in \\boldsymbol{\\mathbb{R}}^{h×q}$的计算为\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
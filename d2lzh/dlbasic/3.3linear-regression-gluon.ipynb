{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 线性回归的简洁实现\n",
    "本节将使⽤MXNet提供的Gluon接口更⽅便地实现线性回归的训练。\n",
    "## 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from mxnet import nd, autograd\n",
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "features = nd.random.normal(shape=(num_examples, num_inputs))\n",
    "labels = true_w[0]*features[:,0] + true_w[1]*features[:,1] + true_b\n",
    "labels += nd.random.normal(scale=0.01,shape=labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "\n[ 4.879625   4.2968144 -3.4331114 11.099875  -3.8235688]\n<NDArray 5 @cpu(0)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "labels.take(nd.array(range(5)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 读取数据\n",
    "Gluon提供了data包来读取数据。由于data常⽤作变量名，我们将导⼊的data模块⽤添加\n",
    "了Gluon⾸字⺟的假名gdata代替。在每⼀次迭代中，我们将随机读取包含10个数据样本的小\n",
    "批量。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from mxnet.gluon import data as gdata\n",
    "batch_size = 10\n",
    "# 将训练数据的特征和标签组合\n",
    "dataset = gdata.ArrayDataset(features, labels)\n",
    "# 随机读取⼩批量\n",
    "data_iter = gdata.DataLoader(dataset, batch_size, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n[[-0.4070257  -0.760578  ]\n [ 1.591328    0.24141619]\n [-0.28439447  1.0559008 ]\n [ 0.50472885 -0.48745614]\n [-0.43371913  1.3150975 ]\n [ 0.22842942  0.62486184]\n [-0.5400787   0.4005976 ]\n [-0.53560084 -0.00894159]\n [-0.4658121  -0.28205368]\n [-0.04197302 -0.08312167]]\n<NDArray 10x2 @cpu(0)> \n[ 5.9727497   6.545585    0.05495567  6.874393   -1.1574751   2.5135262\n  1.7483729   3.1680815   4.217416    4.405445  ]\n<NDArray 10 @cpu(0)>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X, y)\n",
    "    break;\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义模型\n",
    "Gluon提供了⼤量预定义的层，这使我们只需关注使⽤哪些层来构造模型。下⾯将介绍如何使⽤Gluon更简洁地定义线性回归。\n",
    "⾸先，导⼊nn模块。实际上，“nn”是neural networks（神经⽹络）的缩写。顾名思义，该模块定\n",
    "义了⼤量神经⽹络的层。我们先定义⼀个模型变量net，它是⼀个Sequential实例。在Gluon中，\n",
    "Sequential实例可以看作是⼀个串联各个层的容器。在构造模型时，我们在该容器中依次添加\n",
    "层。当给定输⼊数据时，容器中的每⼀层将依次计算并将输出作为下⼀层的输⼊。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "net = nn.Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "回顾线性回归在神经⽹络图中的表⽰。作为⼀个单层神经⽹络，线性回归输出层中的神\n",
    "经元和输⼊层中各个输⼊完全连接。因此，线性回归的输出层⼜叫全连接层。\n",
    "在Gluon中，全连接层是⼀个Dense实例。我们定义该层输出个数为1。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "net.add(nn.Dense(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "值得⼀提的是，在Gluon中我们⽆须指定每⼀层输⼊的形状，例如线性回归的输⼊个数。当模型\n",
    "得到数据时，例如后⾯执⾏net(X)时，模型将⾃动推断出每⼀层的输⼊个数。我们将在之后“深\n",
    "度学习计算”⼀章详细介绍这种机制。 Gluon的这⼀设计为模型开发带来便利\n",
    "## 初始化模型参数\n",
    "在使⽤net前，我们需要初始化模型参数，如线性回归模型中的权重和偏差。我们从MXNet导\n",
    "⼊init模块。该模块提供了模型参数初始化的各种⽅法。这⾥的init是initializer的缩写\n",
    "形式。我们通过init.Normal(sigma=0.01)指定权重参数每个元素将在初始化时随机采样于\n",
    "均值为0、标准差为0.01的正态分布。偏差参数默认会初始化为零。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义损失函数\n",
    "在Gluon中， loss模块定义了各种损失函数。我们⽤假名gloss代替导⼊的loss模块，并直接\n",
    "使⽤它提供的平⽅损失作为模型的损失函数。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from mxnet.gluon import loss as gloss\n",
    "loss = gloss.L2Loss() # 平⽅损失⼜称L2范数损失"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义优化算法\n",
    "在导⼊Gluon后，我们创建⼀个Trainer实例，并指定学习率为0.03的小批量随机梯度下降（sgd）为优化算法。\n",
    "该优化算法将⽤来迭代net实例所有通过add函数嵌套的层所包含的全部参数。这些参数可以通过collect_params函数获取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练模型\n",
    "在使⽤Gluon训练模型时，我们通过调⽤Trainer实例的step函数来迭代模型参数。我\n",
    "们提到，由于变量l是⻓度为batch_size的⼀维NDArray，执⾏l.backward()等价于执⾏l.\n",
    "sum().backward()。按照小批量随机梯度下降的定义，我们在step函数中指明批量⼤小，从\n",
    "而对批量中样本梯度求平均"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "epoch 1, loss 0.000048\n",
      "epoch 2, loss 0.000048\nepoch 3, loss 0.000048\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    for X, y in data_iter:\n",
    "        with autograd.record():\n",
    "            l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "    train_l = loss(net(features), labels)\n",
    "    print('epoch %d, loss %f' % (epoch, train_l.mean().asnumpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下⾯我们分别⽐较学到的模型参数和真实的模型参数。我们从net获得需要的层，并访问其权重\n",
    "（weight）和偏差（bias）。学到的参数和真实的参数很接近。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "([2, -3.4], \n [[ 2.000011 -3.399709]]\n <NDArray 1x2 @cpu(0)>)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "dense = net[0]\n",
    "true_w, dense.weight.data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(4.2, \n [4.200454]\n <NDArray 1 @cpu(0)>)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "true_b, dense.bias.data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使⽤Gluon可以更简洁地实现模型。\n",
    "- 在Gluon中， data模块提供了有关数据处理的⼯具， nn模块定义了⼤量神经⽹络的层，\n",
    "- loss模块定义了各种损失函数。\n",
    "- MXNet的initializer模块提供了模型参数初始化的各种⽅法。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
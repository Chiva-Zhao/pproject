{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 深度卷积神经网络（AlexNet）\n",
    "在LeNet提出后的将近20年⾥，神经⽹络⼀度被其他机器学习⽅法超越，如⽀持向量机。虽\n",
    "然LeNet可以在早期的小数据集上取得好的成绩，但是在更⼤的真实数据集上的表现并不尽如\n",
    "⼈意。⼀⽅⾯，神经⽹络计算复杂。虽然20世纪90年代也有过⼀些针对神经⽹络的加速硬件，但\n",
    "并没有像之后GPU那样⼤量普及。因此，训练⼀个多通道、多层和有⼤量参数的卷积神经⽹络在\n",
    "当年很难完成。另⼀⽅⾯，当年研究者还没有⼤量深⼊研究参数初始化和⾮凸优化算法等诸多领\n",
    "域，导致复杂的神经⽹络的训练通常较困难。\n",
    "\n",
    "我们在上⼀节看到，神经⽹络可以直接基于图像的原始像素进⾏分类。这种称为端到端（end-toend）的⽅法节省了很多中间步骤。然而，在很⻓⼀段时间⾥更流⾏的是研究者通过勤劳与智慧\n",
    "所设计并⽣成的⼿⼯特征。这类图像分类研究的主要流程是：\n",
    "1. 获取图像数据集；\n",
    "2. 使⽤已有的特征提取函数⽣成图像的特征；\n",
    "3. 使⽤机器学习模型对图像的特征分类。\n",
    "\n",
    "当时认为的机器学习部分仅限最后这⼀步。如果那时候跟机器学习研究者交谈，他们会认为机器\n",
    "学习既重要⼜优美。优雅的定理证明了许多分类器的性质。机器学习领域⽣机勃勃、严谨而且极\n",
    "其有⽤。然而，如果跟计算机视觉研究者交谈，则是另外⼀幅景象。他们会告诉你图像识别⾥“不\n",
    "可告⼈”的现实是：计算机视觉流程中真正重要的是数据和特征。也就是说，使⽤较⼲净的数据\n",
    "集和较有效的特征甚⾄⽐机器学习模型的选择对图像分类结果的影响更⼤。\n",
    "## 学习特征表⽰\n",
    "既然特征如此重要，它该如何表⽰呢？\n",
    "\n",
    "我们已经提到，在相当⻓的时间⾥，特征都是基于各式各样⼿⼯设计的函数从数据中提取的。事\n",
    "实上，不少研究者通过提出新的特征提取函数不断改进图像分类结果。这⼀度为计算机视觉的发\n",
    "展做出了重要贡献。\n",
    "\n",
    "然而，另⼀些研究者则持异议。他们认为特征本⾝也应该由学习得来。他们还相信，为了表征⾜\n",
    "够复杂的输⼊，特征本⾝应该分级表⽰。持这⼀想法的研究者相信，多层神经⽹络可能可以学得\n",
    "数据的多级表征，并逐级表⽰越来越抽象的概念或模式。以图像分类为例，并回忆[“⼆维卷积层”](5.1cov-layer.ipynb)\n",
    "⼀节中物体边缘检测的例⼦。在多层神经⽹络中，图像的第⼀级的表⽰可以是在特定的位置和⻆\n",
    "度是否出现边缘；而第⼆级的表⽰说不定能够将这些边缘组合出有趣的模式，如花纹；在第三级\n",
    "的表⽰中，也许上⼀级的花纹能进⼀步汇合成对应物体特定部位的模式。这样逐级表⽰下去，最\n",
    "终，模型能够较容易根据最后⼀级的表⽰完成分类任务。需要强调的是，输⼊的逐级表⽰由多层\n",
    "模型中的参数决定，而这些参数都是学出来的。\n",
    "\n",
    "尽管⼀直有⼀群执着的研究者不断钻研，试图学习视觉数据的逐级表征，然而很⻓⼀段时间⾥这\n",
    "些野⼼都未能实现。这其中有诸多因素值得我们⼀⼀分析\n",
    "### 缺失要素⼀：数据\n",
    "包含许多特征的深度模型需要⼤量的有标签的数据才能表现得⽐其他经典⽅法更好。限于早期计\n",
    "算机有限的存储和90年代有限的研究预算，⼤部分研究只基于小的公开数据集。例如，不少研究\n",
    "论⽂基于加州⼤学欧⽂分校（UCI）提供的若⼲个公开数据集，其中许多数据集只有⼏百⾄⼏千张\n",
    "图像。这⼀状况在2010年前后兴起的⼤数据浪潮中得到改善。特别是， 2009年诞⽣的ImageNet数\n",
    "据集包含了1,000⼤类物体，每类有多达数千张不同的图像。这⼀规模是当时其他公开数据集⽆\n",
    "法与之相提并论的。 ImageNet数据集同时推动计算机视觉和机器学习研究进⼊新的阶段，使此\n",
    "前的传统⽅法不再有优势。\n",
    "### 缺失要素⼆：硬件\n",
    "深度学习对计算资源要求很⾼。早期的硬件计算能⼒有限，这使训练较复杂的神经⽹络变得很困\n",
    "难。然而，通⽤GPU的到来改变了这⼀格局。很久以来， GPU都是为图像处理和计算机游戏设计\n",
    "的，尤其是针对⼤吞吐量的矩阵和向量乘法从而服务于基本的图形变换。值得庆幸的是，这其中\n",
    "的数学表达与深度⽹络中的卷积层的表达类似。通⽤GPU这个概念在2001年开始兴起，涌现出诸\n",
    "如OpenCL和CUDA之类的编程框架。这使得GPU也在2010年前后开始被机器学习社区使⽤\n",
    "## AlexNet\n",
    "2012年， AlexNet横空出世。这个模型的名字来源于论⽂第⼀作者的姓名Alex Krizhevsky [1]。\n",
    "AlexNet使⽤了8层卷积神经⽹络，并以很⼤的优势赢得了ImageNet 2012图像识别挑战赛。它\n",
    "⾸次证明了学习到的特征可以超越⼿⼯设计的特征，从而⼀举打破计算机视觉研究的前状。\n",
    "\n",
    "AlexNet与LeNet的设计理念⾮常相似，但也有显著的区别。\n",
    "\n",
    "第⼀，与相对较小的LeNet相⽐， AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以\n",
    "及1个全连接输出层。下⾯我们来详细描述这些层的设计。\n",
    "\n",
    "AlexNet第⼀层中的卷积窗口形状是11 × 11。因为ImageNet中绝⼤多数图像的⾼和宽均\n",
    "⽐MNIST图像的⾼和宽⼤10倍以上， ImageNet图像的物体占⽤更多的像素，所以需要更⼤的卷\n",
    "积窗口来捕获物体。第⼆层中的卷积窗口形状减小到5 × 5，之后全采⽤3 × 3。此外，第⼀、第⼆\n",
    "和第五个卷积层之后都使⽤了窗口形状为3 × 3、步幅为2的最⼤池化层。而且， AlexNet使⽤的卷\n",
    "积通道数也⼤于LeNet中的卷积通道数数⼗倍。\n",
    "\n",
    "紧接着最后⼀个卷积层的是两个输出个数为4096的全连接层。这两个巨⼤的全连接层带来将近1\n",
    "GB的模型参数。由于早期显存的限制，最早的AlexNet使⽤双数据流的设计使⼀个GPU只需要处\n",
    "理⼀半模型。幸运的是，显存在过去⼏年得到了⻓⾜的发展，因此通常我们不再需要这样的特别设计了\n",
    "\n",
    "第⼆， AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。⼀⽅⾯， ReLU激活函数的\n",
    "计算更简单，例如它并没有sigmoid激活函数中的求幂运算。另⼀⽅⾯， ReLU激活函数在不同的\n",
    "参数初始化⽅法下使模型更容易训练。这是由于当sigmoid激活函数输出极接近0或1时，这些区\n",
    "域的梯度⼏乎为0，从而造成反向传播⽆法继续更新部分模型参数；而ReLU激活函数在正区间的\n",
    "梯度恒为1。因此，若模型参数初始化不当， sigmoid函数可能在正区间得到⼏乎为0的梯度，从\n",
    "而令模型⽆法得到有效训练。\n",
    "\n",
    "第三， AlexNet通过丢弃法（参⻅[“丢弃法”](../3dlbasic/3.13dropout.ipynb) ⼀节）来控制全连接层的模型复杂度。而LeNet并没\n",
    "有使⽤丢弃法。\n",
    "\n",
    "第四， AlexNet引⼊了⼤量的图像增⼴，如翻转、裁剪和颜⾊变化，从而进⼀步扩⼤数据集来缓\n",
    "解过拟合。我们将在后⾯的“图像增⼴” ⼀节详细介绍这种⽅法。\n",
    "\n",
    "下⾯我们实现稍微简化过的AlexNet。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, nn\n",
    "import os\n",
    "import sys\n",
    "\n",
    "net = nn.Sequential()\n",
    "# 使⽤较⼤的11 x 11窗⼝来捕获物体。同时使⽤步幅4来较⼤幅度减⼩输出⾼和宽。这⾥使⽤的输出通\n",
    "# 道数⽐LeNet中的也要⼤很多\n",
    "net.add(nn.Conv2D(channels=96,kernel_size=11,strides=4,activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3,strides=2),\n",
    "        # 减⼩卷积窗⼝，使⽤填充为2来使得输⼊与输出的⾼和宽⼀致，且增⼤输出通道数\n",
    "        nn.Conv2D(channels=256,kernel_size=5,strides=2,activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3,strides=2),\n",
    "        # 连续3个卷积层，且使⽤更⼩的卷积窗⼝。除了最后的卷积层外，进⼀步增⼤了输出通道数。\n",
    "        # 前两个卷积层后不使⽤池化层来减⼩输⼊的⾼和宽\n",
    "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2D(256, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 这⾥全连接层的输出个数⽐LeNet中的⼤数倍。使⽤丢弃层来缓解过拟合\n",
    "        nn.Dense(4096,activation='relu'),nn.Dropout(0.5),\n",
    "        nn.Dense(4096,activation='relu'),nn.Dropout(0.5),\n",
    "        # 输出层。由于这⾥使⽤Fashion-MNIST，所以⽤类别数为10，⽽⾮论⽂中的1000\n",
    "        nn.Dense(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们构造⼀个⾼和宽均为224的单通道数据样本来观察每⼀层的输出形状。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "conv0 output shape\t (1, 96, 54, 54)\n",
      "pool0 output shape\t (1, 96, 26, 26)\n",
      "conv1 output shape\t (1, 256, 11, 11)\n",
      "pool1 output shape\t (1, 256, 5, 5)\n",
      "conv2 output shape\t (1, 384, 5, 5)\n",
      "conv3 output shape\t (1, 384, 5, 5)\n",
      "conv4 output shape\t (1, 256, 5, 5)\n",
      "pool2 output shape\t (1, 256, 2, 2)\n",
      "dense0 output shape\t (1, 4096)\n",
      "dropout0 output shape\t (1, 4096)\n",
      "dense1 output shape\t (1, 4096)\n",
      "dropout1 output shape\t (1, 4096)\n",
      "dense2 output shape\t (1, 10)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "X = nd.random.uniform(shape=(1,1,224,224))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape\\t', X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 读取数据\n",
    "虽然论⽂中AlexNet使⽤ImageNet数据集，但因为ImageNet数据集训练时间较⻓，我们仍⽤\n",
    "前⾯的Fashion-MNIST数据集来演⽰AlexNet。读取数据的时候我们额外做了⼀步将图像⾼和\n",
    "宽扩⼤到AlexNet使⽤的图像⾼和宽224。这个可以通过Resize实例来实现。也就是说，我们\n",
    "在ToTensor实例前使⽤Resize实例，然后使⽤Compose实例来将这两个变换串联以⽅便调⽤。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n",
    "\t\t'~', '.mxnet', 'datasets', 'fashion-mnist')):\n",
    "\troot = os.path.expanduser(root)  # 展开用户路径'~'\n",
    "\ttransformer = []\n",
    "\tif resize:\n",
    "\t\ttransformer += [gdata.vision.transforms.Resize(resize)]\n",
    "\ttransformer += [gdata.vision.transforms.ToTensor()]\n",
    "\ttransformer = gdata.vision.transforms.Compose(transformer)\n",
    "\tmnist_train = gdata.vision.FashionMNIST(root=root, train=True)\n",
    "\tmnist_test = gdata.vision.FashionMNIST(root=root, train=False)\n",
    "\tnum_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\ttrain_iter = gdata.DataLoader(\n",
    "\t\tmnist_train.transform_first(transformer), batch_size, shuffle=True,\n",
    "\t\tnum_workers=num_workers)\n",
    "\ttest_iter = gdata.DataLoader(\n",
    "\t\tmnist_test.transform_first(transformer), batch_size, shuffle=False,\n",
    "\t\tnum_workers=num_workers)\n",
    "\treturn train_iter, test_iter\n",
    "\n",
    "batch_size = 128\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练\n",
    "这时候我们可以开始训练AlexNet了。相对于上⼀节的LeNet，这⾥的主要改动是使⽤了更小的学习率。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "training on cpu(0)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lr, num_epochs, ctx = 0.01, 5, d2l.try_gpu()\n",
    "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ⼩结\n",
    "- AlexNet跟LeNet结构类似，但使⽤了更多的卷积层和更⼤的参数空间来拟合⼤规模数据\n",
    "集ImageNet。它是浅层神经⽹络和深度神经⽹络的分界线。\n",
    "- 虽然看上去AlexNet的实现⽐LeNet的实现也就多了⼏⾏代码而已，但这个观念上的转变和\n",
    "真正优秀实验结果的产⽣令学术界付出了很多年。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
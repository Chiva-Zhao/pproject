{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# GPU计算\n",
    "到⽬前为⽌，我们⼀直在使⽤CPU计算。对复杂的神经⽹络和⼤规模的数据来说，使⽤CPU来计\n",
    "算可能不够⾼效。在本节中，我们将介绍如何使⽤单块NVIDIA GPU来计算。⾸先，需要确保已\n",
    "经安装好了⾄少⼀块NVIDIA GPU。然后，下载CUDA并按照提⽰设置好相应的路径（可参考附录\n",
    "中“使⽤AWS运⾏代码” ⼀节）。这些准备⼯作都完成后，下⾯就可以通过nvidia-smi命令来查\n",
    "看显卡信息了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "'nvidia-smi' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "!nvidia-smi # 对Linux/macOS⽤⼾有效"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来，我们需要确认安装了MXNet的GPU版本。安装⽅法⻅“获取和运⾏本书的代码” ⼀节。\n",
    "运⾏本节中的程序需要⾄少2块GPU。\n",
    "## 计算设备\n",
    "MXNet可以指定⽤来存储和计算的设备，如使⽤内存的CPU或者使⽤显存的GPU。默认情况下，\n",
    "MXNet会将数据创建在内存，然后利⽤CPU来计算。在MXNet中， mx.cpu()（或者在括号⾥填任\n",
    "意整数）表⽰所有的物理CPU和内存。这意味着， MXNet的计算会尽量使⽤所有的CPU核。但mx.\n",
    "gpu()只代表⼀块GPU和相应的显存。如果有多块GPU，我们⽤mx.gpu(i)来表⽰第i块GPU及\n",
    "相应的显存（i从0开始）且mx.gpu(0)和mx.gpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(cpu(0), gpu(0), gpu(1))"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "mx.cpu(), mx.gpu(), mx.gpu(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NDArray的GPU计算\n",
    "在默认情况下， NDArray存在内存上。因此，之前我们每次打印NDArray的时候都会看\n",
    "到@cpu(0)这个标识。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "\n[1. 2. 3.]\n<NDArray 3 @cpu(0)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "x = nd.array([1, 2, 3])\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以通过NDArray的context属性来查看该NDArray所在的设备。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "cpu(0)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "x.context"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPU上的存储\n",
    "我们有多种⽅法将NDArray存储在显存上。例如，我们可以在创建NDArray的时候通过ctx参数\n",
    "指定存储设备。下⾯我们将NDArray变量a创建在gpu(0)上。注意，在打印a时，设备信息变成\n",
    "了@gpu(0)。创建在显存上的NDArray只消耗同⼀块显卡的显存。我们可以通过nvidia-smi命\n",
    "令查看显存的使⽤情况。通常，我们需要确保不创建超过显存上限的数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "\n[1. 2. 3.]\n<NDArray 3 @cpu(0)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "a = nd.array([1, 2, 3], ctx=mx.gpu())\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "假设⾄少有2块GPU，下⾯代码将会在gpu(1)上创建随机数组"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "B = nd.random.uniform(shape=(2, 3), ctx=mx.gpu(1))\n",
    "B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "除了在创建时指定，我们也可以通过copyto函数和as_in_context函数在设备之间传输数据。\n",
    "下⾯我们将内存上的NDArray变量x复制到gpu(0)上。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "\n[1. 2. 3.]\n<NDArray 3 @cpu(0)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "y = x.copyto(mx.gpu())\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z = x.as_in_context(mx.gpu())\n",
    "z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "需要区分的是，如果源变量和⽬标变量的context⼀致， as_in_context函数使⽬标变量和源\n",
    "变量共享源变量的内存或显存。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y.as_in_context(mx.gpu()) is y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "而copyto函数总是为⽬标变量开新的内存或显存"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y.copyto(mx.gpu()) is y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPU上的计算\n",
    "MXNet的计算会在数据的context属性所指定的设备上执⾏。为了使⽤GPU计算，我们只需要事\n",
    "先将数据存储在显存上。计算结果会⾃动保存在同⼀块显卡的显存上。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(z+2).exp()*y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "注意，MXNet要求计算的所有输⼊数据都在内存或同⼀块显卡的显存上。这样设计的原因是CPU和\n",
    "不同的GPU之间的数据交互通常⽐较耗时。因此， MXNet希望⽤⼾确切地指明计算的输⼊数据都\n",
    "在内存或同⼀块显卡的显存上。例如，如果将内存上的NDArray变量x和显存上的NDArray变\n",
    "量y做运算，会出现错误信息。当我们打印NDArray或将NDArray转换成NumPy格式时，如果数\n",
    "据不在内存⾥， MXNet会将它先复制到内存，从而造成额外的传输开销。\n",
    "## Gluon的GPU计算\n",
    "同NDArray类似， Gluon的模型可以在初始化时通过ctx参数指定设备。下⾯的代码将模型参数\n",
    "初始化在显存上。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(1))\n",
    "net.initialize(ctx=mx.gpu())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "当输⼊是显存上的NDArray时， Gluon会在同⼀块显卡的显存上计算结果。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下⾯我们确认⼀下模型参数存储在同⼀块显卡的显存上"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net[0].weight.data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ⼩结\n",
    "- MXNet可以指定⽤来存储和计算的设备，如使⽤内存的CPU或者使⽤显存的GPU。在默认\n",
    "情况下, MXNet会将数据创建在内存，然后利⽤CPU来计算。\n",
    "- MXNet要求计算的所有输⼊数据都在内存或同⼀块显卡的显存上。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
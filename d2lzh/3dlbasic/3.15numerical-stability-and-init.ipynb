{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 数值稳定性和模型初始化\n",
    "理解了正向传播与反向传播以后，我们来讨论⼀下深度学习模型的数值稳定性问题以及模型参数\n",
    "的初始化⽅法。深度模型有关数值稳定性的典型问题是衰减（vanishing）和爆炸（explosion）。\n",
    "## 衰减和爆炸\n",
    "当神经网络的层数较多时，模型的数值稳定性容易变差。假设一个层数为$L$的多层感知机的\n",
    "第$l$层$\\boldsymbol{H}^{(l)}$的权重参数为$\\boldsymbol{W}^{(l)}$，\n",
    "输出层$\\boldsymbol{H}^{(L)}$的权重参数为$\\boldsymbol{W}^{(L)}$。\n",
    "为了便于讨论，不考虑偏差参数，且设所有隐藏层的激活函数为恒等映射（identity mapping）\n",
    "$\\phi(x) = x$。给定输入$\\boldsymbol{X}$，多层感知机的第$l$层的输\n",
    "出$\\boldsymbol{H}^{(l)} = \\boldsymbol{X} \\boldsymbol{W}^{(1)} \\boldsymbol{W}^{(2)} \\ldots \\boldsymbol{W}^{(l)}$。\n",
    "此时，如果层数$l$较大，$\\boldsymbol{H}^{(l)}$的计算可能会出现衰减或爆炸。\n",
    "举个例子，假设输入和所有层的权重参数都是标量，如权重参数为0.2和5，\n",
    "多层感知机的第30层输出为输入$\\boldsymbol{X}$分别\n",
    "与$0.2^{30} \\approx 1 \\times 10^{-21}$（衰减）和$5^{30} \\approx 9 \\times 10^{20}$（爆炸）的乘积。\n",
    "类似地，当层数较多时，梯度的计算也更容易出现衰减或爆炸。\n",
    "随着内容的不断深⼊，我们会在后⾯的章节进⼀步介绍深度学习的数值稳定性问题以及解决⽅法。\n",
    "## 随机初始化模型参数\n",
    "在神经⽹络中，通常需要随机初始化模型参数。下⾯我们来解释这样做的原因。\n",
    "\n",
    "回顾[“多层感知机”](3.8mlp.ipynb) ⼀节图3.3描述的多层感知机。为了⽅便解释，假设输出层只保留⼀个输出单\n",
    "元$o_1（删去o_2和o_3$以及指向它们的箭头），且隐藏层使⽤相同的激活函数。如果将每个隐藏单元的\n",
    "参数都初始化为相等的值，那么在正向传播时每个隐藏单元将根据相同的输⼊计算出相同的值，\n",
    "并传递⾄输出层。在反向传播中，每个隐藏单元的参数梯度值相等。因此，这些参数在使⽤基于\n",
    "梯度的优化算法迭代后值依然相等。之后的迭代也是如此。在这种情况下，⽆论隐藏单元有多少，\n",
    "隐藏层本质上只有1个隐藏单元在发挥作⽤。因此，正如在前⾯的实验中所做的那样，我们通常\n",
    "将神经⽹络的模型参数，特别是权重参数，进⾏随机初始化。\n",
    "### MXNet的默认随机初始化\n",
    "随机初始化模型参数的⽅法有很多。在[“线性回归的简洁实现”](3.3linear-regression-gluon.ipynb) ⼀节中，我们使⽤`net.\n",
    "initialize(init.Normal(sigma=0.01))`使模型net的权重参数采⽤正态分布的随机初始\n",
    "化⽅式。如果不指定初始化⽅法，如net.initialize()， MXNet将使⽤默认的随机初始化⽅\n",
    "法：权重参数每个元素随机采样于-0.07到0.07之间的均匀分布，偏差参数全部清零。\n",
    "### Xavier随机初始化\n",
    "还有⼀种⽐较常⽤的随机初始化⽅法叫作Xavier随机初始化。假设某全连接层的输⼊个数为a，\n",
    "输出个数为b， Xavier随机初始化将使该层中权重参数的每个元素都随机采样于均匀分布\n",
    "$U=\\left(-\\sqrt {\\frac 6{a+b}},\\sqrt \\frac 6{a+b} \\right)$\n",
    "它的设计主要考虑到，模型参数初始化后，每层输出的⽅差不该受该层输⼊个数影响，且每层梯\n",
    "度的⽅差也不该受该层输出个数影响。\n",
    "## ⼩结\n",
    "- 深度模型有关数值稳定性的典型问题是衰减和爆炸。当神经⽹络的层数较多时，模型的数值稳定性容易变差。\n",
    "- 我们通常需要随机初始化神经⽹络的模型参数，如权重参数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}